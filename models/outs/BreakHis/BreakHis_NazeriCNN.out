Wed May 26 22:16:31 BST 2021
cgpu01.maxwell.local

Currently Loaded Modules:
  1) slurm/current   2) cudatoolkit-10.1.168

 

/tmp/slurmd/job790565/slurm_script: line 20: activate: No such file or directory
Wed May 26 22:16:33 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.51.05    Driver Version: 450.51.05    CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce RTX 208...  Off  | 00000000:2F:00.0 Off |                  N/A |
| 31%   44C    P0    66W / 250W |      0MiB / 11019MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  GeForce RTX 208...  Off  | 00000000:86:00.0 Off |                  N/A |
| 36%   43C    P0    24W / 250W |      0MiB / 11019MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
PatchWiseModel(
  (features): Sequential(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(16, 16, kernel_size=(2, 2), stride=(2, 2))
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU(inplace=True)
    (15): Conv2d(32, 32, kernel_size=(2, 2), stride=(2, 2))
    (16): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (23): ReLU(inplace=True)
    (24): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2))
    (25): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))
  )
  (classifier): Sequential(
    (0): Linear(in_features=12288, out_features=2, bias=True)
  )
)
Parameters: 119141
Trainable parameters: 119141
Using: cuda
GeForce RTX 2080 Ti
Memory Usage:
Allocated: 0.0 GB
Cached:    0.0 GB
Start training network: 2021/05/26 22:16

Using  22144 training samples
Using  1186 validation samples
Epoch 1/2
----------
train Loss: 0.4334 Acc: 0.8249
val Loss: 0.3220 Acc: 0.8609
Epoch 2/2
----------
train Loss: 0.3321 Acc: 0.8624
val Loss: 0.2966 Acc: 0.8727
Training complete in 50m 42s
Best Validation Accuracy: 0.872681
Test Accuracy of the model: 0.90
Confusion matrix
 tensor([[283.,  83.],
        [ 41., 780.]])
Class 0
TP 283.0, TN 780.0, FP 41.0, FN 83.0
Sensitivity 0.77, Specificity 0.95, F1 0.82, Accuracy 0.90
Class 1
TP 780.0, TN 283.0, FP 83.0, FN 41.0
Sensitivity 0.95, Specificity 0.77, F1 0.93, Accuracy 0.90
Training Accuracy of the model: 0.90
Model saved: /uoa/home/u02mv17/Repository/models/_BreakHis_patchwise__BreakHis_patchwise_2021-05-26_22-16.ckpt
NazeriCNN(
  (patch_wise_model): PatchWiseModel(
    (features): Sequential(
      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(16, 16, kernel_size=(2, 2), stride=(2, 2))
      (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (11): ReLU(inplace=True)
      (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (14): ReLU(inplace=True)
      (15): Conv2d(32, 32, kernel_size=(2, 2), stride=(2, 2))
      (16): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (17): ReLU(inplace=True)
      (18): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (20): ReLU(inplace=True)
      (21): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (22): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (23): ReLU(inplace=True)
      (24): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2))
      (25): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (26): ReLU(inplace=True)
      (27): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))
    )
    (classifier): Sequential(
      (0): Linear(in_features=12288, out_features=2, bias=True)
    )
  )
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2))
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): ReLU(inplace=True)
    (15): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2))
    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
  (classifier): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=128, out_features=128, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=128, out_features=64, bias=True)
    (7): ReLU(inplace=True)
    (8): Dropout(p=0.5, inplace=False)
    (9): Linear(in_features=64, out_features=2, bias=True)
  )
)
Parameters: 520488
Trainable parameters: 520488
Using: cuda
GeForce RTX 2080 Ti
Memory Usage:
Allocated: 0.0 GB
Cached:    1.2 GB
Start training network: 2021/05/26 23:09

Using  44288 training samples
Using  1186 validation samples
Epoch 1/10
----------
train Loss: 0.3262 Acc: 0.8654
val Loss: 0.3191 Acc: 0.8558
Epoch 2/10
----------
train Loss: 0.2801 Acc: 0.8825
val Loss: 0.2335 Acc: 0.8988
Epoch 3/10
----------
train Loss: 0.2489 Acc: 0.8977
val Loss: 0.2063 Acc: 0.9098
Epoch 4/10
----------
train Loss: 0.2366 Acc: 0.9034
val Loss: 0.2666 Acc: 0.8862
Epoch 5/10
----------
train Loss: 0.2286 Acc: 0.9076
val Loss: 0.2621 Acc: 0.8929
Epoch 6/10
----------
train Loss: 0.2192 Acc: 0.9145
val Loss: 0.2127 Acc: 0.9013
Epoch 7/10
----------
train Loss: 0.2172 Acc: 0.9149
val Loss: 0.2071 Acc: 0.9148
Epoch 8/10
----------
train Loss: 0.1961 Acc: 0.9217
val Loss: 0.1812 Acc: 0.9241
Epoch 9/10
----------
train Loss: 0.2013 Acc: 0.9197
val Loss: 0.2069 Acc: 0.9115
Epoch 10/10
----------
train Loss: 0.1807 Acc: 0.9297
val Loss: 0.2146 Acc: 0.9115
Training complete in 252m 5s
Best Validation Accuracy: 0.924115
Test Accuracy of the model: 0.94
Confusion matrix
 tensor([[346.,  20.],
        [ 53., 768.]])
Class 0
TP 346.0, TN 768.0, FP 53.0, FN 20.0
Sensitivity 0.95, Specificity 0.94, F1 0.90, Accuracy 0.94
Class 1
TP 768.0, TN 346.0, FP 20.0, FN 53.0
Sensitivity 0.94, Specificity 0.95, F1 0.95, Accuracy 0.94
Training Accuracy of the model: 0.94
Model saved: /uoa/home/u02mv17/Repository/models/_BreakHis_NazeriCNN__BreakHis_NazeriCNN_2021-05-26_23-09.ckpt
Thu May 27 03:23:49 BST 2021
